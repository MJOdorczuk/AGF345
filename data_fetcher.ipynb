{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGF-345\n",
    "Polar Magnetospheric Substorms\n",
    "\n",
    "## Auroral Acceleration - Data Fetcher\n",
    "\n",
    "### Authors\n",
    "\n",
    " - Martin Claude Joseph Baudry\n",
    " - Jeanne Longlune\n",
    " - Michał Jan Odorczuk\n",
    " - Inés Eleonor Santandreu Ros\n",
    " - Ana Filipa Sousa Barros\n",
    "\n",
    "### Description\n",
    "\n",
    "This notebook automates downloading all the necessary data for the project analysis.\n",
    "\n",
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tsyganenko modelled magnetic field lines\n",
    "\n",
    "Automatically fetches the data from [here](https://ccmc.gsfc.nasa.gov/requests/instant/tsyganenko.php) and saves it in the data/Tsy/(DAY)_(HOUR) location, where DAY is the day of the year (assumed to be 2015 in the model) and HOUR is the hour of the day.\n",
    "\n",
    "#### Invariant metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to which the form is submitted\n",
    "url = \"https://ccmc.gsfc.nasa.gov/requests/instant/tsyganenko_results.php\"\n",
    "\n",
    "# Headers (based on your provided manual POST request)\n",
    "headers = {\n",
    "    'Host': 'ccmc.gsfc.nasa.gov',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:132.0) Gecko/20100101 Firefox/132.0',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "    'Content-Type': 'application/x-www-form-urlencoded',\n",
    "    'Origin': 'https://ccmc.gsfc.nasa.gov',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://ccmc.gsfc.nasa.gov/requests/instant/tsyganenko.php',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Priority': 'u=0',\n",
    "}\n",
    "\n",
    "locations = {\n",
    "    'LYR': (78.222, 15.648),\n",
    "    'BJR': (74.443, 19.016),\n",
    "    'TRM': (69.650, 18.955)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_fmt = pd.read_fwf(\"data/omni.fmt\", skiprows=4, index_col = 0, names = [\"index\", \"name\", \"format\"])\n",
    "omni_fmt['name'] = omni_fmt['name'].str.split(',').str[0]\n",
    "omni_data = pd.read_fwf(\"data/omni.lst\", names = omni_fmt[\"name\"])\n",
    "\n",
    "\n",
    "\n",
    "def get_omni_data(day, hour, time_shift = True):\n",
    "    if time_shift:\n",
    "        hour -= 1\n",
    "    if hour < 0:\n",
    "        day -= 1\n",
    "        hour = 23\n",
    "    data = omni_data[(omni_data['DOY'] == day)&(omni_data['Hour'] == hour)].iloc[0]\n",
    "    return {\"By\": data[\"BY\"], \"Bz\": data[\"BZ\"], \"v\": data[\"SW Plasma Speed\"], \"p\": data[\"Flow pressure\"], \"Dst\": data[\"Dst-index\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'LYR'\n",
    "lat, lon = locations[location]\n",
    "\n",
    "def get_request_data(day, hour, location, model_version, time_shift = True):\n",
    "    lat, lon = locations[location]\n",
    "    omni_data = get_omni_data(day, hour, time_shift)\n",
    "    return {\n",
    "        'ts_version': model_version,\n",
    "        'Year': '2015',\n",
    "        'Day': day,\n",
    "        'Hour': hour,\n",
    "        'Minute': '00',\n",
    "        'Second': '00',\n",
    "        'SW dynamic pressure': omni_data['p'],\n",
    "        'SW velocity': omni_data['v'],\n",
    "        'IMF By': omni_data['By'],\n",
    "        'IMF Bz': omni_data['Bz'],\n",
    "        'Dst': omni_data['Dst'],\n",
    "        'DIR': '1',\n",
    "        'Geographic Geocentric Latitude': lat,\n",
    "        'Longitude': lon,\n",
    "        'Xgsm': '1.',\n",
    "        'Ygsm': '1.',\n",
    "        'Zgsm': '1.',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_datafile(day, hour, location, model_version='01', time_shift = True):\n",
    "    # Send the POST request\n",
    "    data = get_request_data(day, hour, location, model_version, time_shift)\n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "\n",
    "    # Parse the HTML response to find the download link\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    link = None\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        if \"MF_LINE_GSM\" in a['href']:\n",
    "            link = a['href']\n",
    "            break\n",
    "\n",
    "    if link:\n",
    "        # Ensure the link is absolute\n",
    "        download_url = f\"https://ccmc.gsfc.nasa.gov{link}\"\n",
    "\n",
    "        # Download the file\n",
    "        file_response = requests.get(download_url)\n",
    "        if file_response.status_code == 200:\n",
    "            # Save the file\n",
    "            if not os.path.isdir(\"data\"):\n",
    "                os.mkdir(\"data\")\n",
    "            if not os.path.isdir(\"data/Tsy\"):\n",
    "                os.mkdir(\"data/Tsy\")\n",
    "            parent = f\"data/Tsy/{day}_{hour:02d}\"\n",
    "            if not os.path.isdir(parent):\n",
    "                os.mkdir(parent)\n",
    "            filename = parent + f\"/B_{day}_2015_T{model_version}_{location}_{hour:02d}.txt\"\n",
    "            with open(filename, 'wb') as file:\n",
    "                file.write(file_response.content)\n",
    "            print(f\"File downloaded successfully and saved as {filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download the file, status code: {file_response.status_code}\")\n",
    "    else:\n",
    "        print(\"Download link not found in the response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully and saved as data/Tsy/311_00/B_311_2015_T01_LYR_00.txt\n",
      "File downloaded successfully and saved as data/Tsy/311_00/B_311_2015_T01_BJR_00.txt\n",
      "File downloaded successfully and saved as data/Tsy/311_00/B_311_2015_T01_TRM_00.txt\n",
      "File downloaded successfully and saved as data/Tsy/311_17/B_311_2015_T01_LYR_17.txt\n",
      "File downloaded successfully and saved as data/Tsy/311_17/B_311_2015_T01_BJR_17.txt\n",
      "File downloaded successfully and saved as data/Tsy/311_17/B_311_2015_T01_TRM_17.txt\n"
     ]
    }
   ],
   "source": [
    "for hour in [0, 17]:\n",
    "    for location in locations.keys():\n",
    "        fetch_datafile(311, hour, location, model_version='01', time_shift=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
